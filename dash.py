import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import os
import torch
import torchvision
import torch.nn as nn
import torch.nn.functional as F
import urllib.request
from PIL import Image
import numpy as np
import warnings
import plotly.graph_objects as go
import gc
import threading
import time
from utils import preprocess_image, resize_and_colorize_mask, FPN_Segmenter, FPN_ConvNeXtV2_Segmenter, CLASS_COLORS

warnings.filterwarnings("ignore", category=UserWarning, module="torch")

st.markdown(
    """
    <style>
        /* Changer la couleur des titres */
        h1, h2, h3, h4, h5, h6 {
            color: #1E90FF !important;
        }

        /* Style des tableaux */
        table {
            background-color: #121212 !important;
            color: #FFFFFF !important;
            border-radius: 10px;
        }

        /* Style des images pour les rendre visibles */
        img {
            border-radius: 10px;
            background-color: #000000;
        }

        /* Style des boutons */
        button {
            background-color: #1E90FF !important;
            color: #FFFFFF !important;
            border-radius: 5px;
        }
    </style>
    """,
    unsafe_allow_html=True
)

# üîπ Configuration du bucket GCS (Public)
BUCKET_NAME = "p9-dashboard-storage"
IMAGE_FOLDER = "Dataset/images"
MASK_FOLDER = "Dataset/masks"

# üîπ Chemins vers les mod√®les sur GCS
FPN_MODEL_URL = f"https://storage.googleapis.com/{BUCKET_NAME}/Models/fpn_best.pth"
CONVNEXT_MODEL_URL = f"https://storage.googleapis.com/{BUCKET_NAME}/Models/convnext_model_fp16.pth"

# üîπ T√©l√©chargement et chargement des mod√®les
@st.cache_resource
def load_models():
    """T√©l√©charge et charge les mod√®les depuis Google Cloud Storage."""
    fpn_model_path = "fpn_best.pth"
    convnext_model_path = "convnext_model_fp16.pth"

    # T√©l√©charger les fichiers depuis GCS s'ils ne sont pas d√©j√† pr√©sents
    if not os.path.exists(fpn_model_path):
        urllib.request.urlretrieve(FPN_MODEL_URL, fpn_model_path)
    
    if not os.path.exists(convnext_model_path):
        urllib.request.urlretrieve(CONVNEXT_MODEL_URL, convnext_model_path)

    # Charger les mod√®les
    fpn_model = torch.load(fpn_model_path, map_location=torch.device("cpu"))
    fpn_model.eval()  # Mettre en mode √©valuation

    convnext_model = torch.load(convnext_model_path, map_location=torch.device("cpu"))
    convnext_model.eval()  # Mettre en mode √©valuation

    return fpn_model, convnext_model

# Charger les mod√®les
fpn_model, convnext_model = load_models()

# üîπ Liste manuelle des images (√©vite les appels √† GCS)
@st.cache_data
def get_available_images_and_masks():
    """Retourne les noms des images et masques pr√©sents dans GCS."""
    available_images = [
        "lindau_000001_000019_leftImg8bit.png",
        "lindau_000002_000019_leftImg8bit.png",
        "lindau_000003_000019_leftImg8bit.png",
        "lindau_000004_000019_leftImg8bit.png",
        "lindau_000005_000019_leftImg8bit.png",
    ]

    available_masks = [
        "lindau_000001_000019_gtFine_color.png",
        "lindau_000002_000019_gtFine_color.png",
        "lindau_000003_000019_gtFine_color.png",
        "lindau_000004_000019_gtFine_color.png",
        "lindau_000005_000019_gtFine_color.png",
    ]

    return available_images, available_masks

available_images, available_masks = get_available_images_and_masks()

# Stocker les r√©sultats de segmentation et l'√©tat du traitement
if "segmentation_result" not in st.session_state:
    st.session_state.segmentation_result = None
if "processing" not in st.session_state:
    st.session_state.processing = False

# üîπ Sidebar Navigation
st.sidebar.title("Menu")
page = st.sidebar.radio("Aller √† :", ["EDA", "R√©sultats des mod√®les", "Test des mod√®les"])

# üîπ Page EDA
if page == "EDA":
    st.title("Exploratory Data Analysis (EDA)")

    # üîπ Structure du dataset
    st.header("Structure des Dossiers et Fichiers")
    folders = {"Images": ["train", "val", "test"], "Masques": ["train", "val", "test"]}
    for key, values in folders.items():
        st.write(f"**{key}**: {', '.join(values)}")

    dataset_info = {
        "Ensemble": ["Train", "Validation", "Test"],
        "Images": [2975, 500, 1525],
        "Masques": [2975, 500, 1525]
    }
    df_info = pd.DataFrame(dataset_info)
    st.table(df_info)

    # üîπ Distribution des classes
    st.header("Distribution des Classes dans les Masques")
    class_distribution = {
        "ID": [7, 11, 21, 26, 8, 1, 23, 3, 4, 2, 6, 17, 24, 22, 13, 9, 12, 20, 33, 15],
        "Classe": ["road", "fence", "truck", "void", "sidewalk", "ego vehicle", "train", "out of roi", "static", "rectification border",
                    "ground", "sky", "motorcycle", "bus", "traffic light", "building", "pole", "car", "void", "vegetation"],
        "Pixels": [2036416525, 1260636120, 879783988, 386328286, 336090793, 286002726, 221979646, 94111150, 83752079, 81359604,
                    75629728, 67789506, 67326424, 63949536, 48454166, 39065130, 36199498, 30448193, 22861233, 17860177]
    }
    df_classes = pd.DataFrame(class_distribution)
    st.table(df_classes.head(10))

    # üîπ Affichage du graphique de r√©partition des classes
    fig, ax = plt.subplots()
    ax.bar(df_classes["Classe"], df_classes["Pixels"], color="skyblue")
    plt.xticks(rotation=90)
    plt.xlabel("Classes")
    plt.ylabel("Nombre de Pixels")
    plt.title("R√©partition des Pixels par Classe")
    st.pyplot(fig)

# üîπ Page R√©sultats des mod√®les
@st.cache_data
def load_results():
    fpn_results = pd.read_csv(f"https://storage.googleapis.com/{BUCKET_NAME}/Resultats/fpn_results.csv")
    mask2former_results = pd.read_csv(f"https://storage.googleapis.com/{BUCKET_NAME}/Resultats/mask2former_results.csv")
    return fpn_results, mask2former_results

fpn_results, mask2former_results = load_results()

if page == "R√©sultats des mod√®les":
    st.title("Analyse des R√©sultats des Mod√®les")

    fig = go.Figure()
    fig.add_trace(go.Scatter(x=fpn_results["Epoch"], y=fpn_results["Val Loss"], mode='lines', name='FPN - Validation Loss'))
    fig.add_trace(go.Scatter(x=fpn_results["Epoch"], y=fpn_results["Val IoU"], mode='lines', name='FPN - Validation IoU Score'))
    fig.add_trace(go.Scatter(x=mask2former_results["Epoch"], y=mask2former_results["Val Loss"], mode='lines', name='Mask2Former - Validation Loss'))
    fig.add_trace(go.Scatter(x=mask2former_results["Epoch"], y=mask2former_results["Val IoU"], mode='lines', name='Mask2Former - Validation IoU Score'))

    st.plotly_chart(fig)

def run_segmentation(model_choice, tensor_image, original_size):
    """Ex√©cute la segmentation en arri√®re-plan"""
    print("üöÄ D√©but de la segmentation...")  # Ajout pour debug
    st.session_state.processing = True  # Indique que la segmentation est en cours
    time.sleep(1)  # Simule un petit d√©lai avant ex√©cution

    with torch.no_grad():
        if model_choice == "FPN":
            output = fpn_model(tensor_image)  # FPN en FP32
        else:
            output = convnext_model(tensor_image.half())  # ConvNeXt en FP16
    
    mask = torch.argmax(output, dim=1).squeeze().cpu().numpy()
    mask_colorized = resize_and_colorize_mask(mask, original_size, CLASS_COLORS)

    # Stocker le r√©sultat et arr√™ter le mode "en cours"
    st.session_state.segmentation_result = mask_colorized
    st.session_state.processing = False
    print("Segmentation termin√©e.")  # Ajout pour debug

# Initialisation des variables dans session_state si elles n'existent pas encore
if "segmentation_fpn" not in st.session_state:
    st.session_state.segmentation_fpn = None

if "segmentation_convnext" not in st.session_state:
    st.session_state.segmentation_convnext = None

# üîπ Page Test des mod√®les
if page == "Test des mod√®les":
    st.title("Test de Segmentation avec les Mod√®les")

    image_choice = st.selectbox("Choisissez une image √† segmenter", available_images)

    # üîπ URL de l‚Äôimage et du masque r√©el
    image_url = f"https://storage.googleapis.com/{BUCKET_NAME}/{IMAGE_FOLDER}/{image_choice}"

    try:
        # üîπ Chargement et affichage de l‚Äôimage d‚Äôentr√©e
        image = Image.open(urllib.request.urlopen(image_url)).convert("RGB")
        st.image(image, caption="Image d'entr√©e", use_container_width=True)

        # üîπ Pr√©traitement de l‚Äôimage avant passage dans le mod√®le
        input_size = (512, 512)
        image_resized, original_size = preprocess_image(image, input_size)
        tensor_image = torch.tensor(image_resized).permute(0, 3, 1, 2).float()

        # üîπ Bouton pour lancer la segmentation
        if st.button("Lancer la segmentation"):
            print("üñ±Ô∏è Bouton cliqu√© !")  # Debug

            # R√©initialiser le r√©sultat pr√©c√©dent
            st.session_state.segmentation_fpn = None
            st.session_state.segmentation_convnext = None

            # üîπ Afficher un spinner pendant l'ex√©cution
            with st.spinner("Segmentation en cours..."):
                run_segmentation(tensor_image, original_size)

            print("Segmentation termin√©e !")  # Debug

        # üîπ Affichage du statut
        if st.session_state.processing:
            st.info("Segmentation en cours... Vous pouvez naviguer librement.")

        # üîπ Afficher les images segment√©es superpos√©es uniquement si elles existent
        if st.session_state.segmentation_fpn is not None and st.session_state.segmentation_convnext is not None:
            col1, col2 = st.columns(2)
            
            with col1:
                st.image(st.session_state.segmentation_fpn, caption="Superposition - FPN", use_container_width=True)

            with col2:
                st.image(st.session_state.segmentation_convnext, caption="Superposition - ConvNeXt", use_container_width=True)

    except Exception as e:
        st.error(f"Erreur lors du chargement des images : {e}")
